{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8b89c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c16bbf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 50)\n",
    "        self.fc2 = nn.Linear(50, 6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(F.relu(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (4, 4),\n",
    "    (5, 5),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (4, 4),\n",
    "    (5, 5),\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (4, 4),\n",
    "    (5, 5),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (4, 4),\n",
    "    (5, 5),\n",
    "    (4, 5),\n",
    "    (5, 0),\n",
    "    (0, 1),\n",
    "    (0, 1),\n",
    "    (5, 0),\n",
    "    (0, 0),\n",
    "    (0, 0),\n",
    "    (1, 1),\n",
    "    (2, 2),\n",
    "    (3, 3),\n",
    "    (4, 4),\n",
    "    (5, 5),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "    (5, 1),\n",
    "    (1, 2),\n",
    "    (2, 3),\n",
    "    (3, 4),\n",
    "    (4, 5),\n",
    "]\n",
    "data = torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 1.8025559186935425\n",
      "Epoch [2/15], Loss: 1.800750970840454\n",
      "Epoch [3/15], Loss: 1.798933982849121\n",
      "Epoch [4/15], Loss: 1.7971326112747192\n",
      "Epoch [5/15], Loss: 1.7953746318817139\n",
      "Epoch [6/15], Loss: 1.7936865091323853\n",
      "Epoch [7/15], Loss: 1.792089819908142\n",
      "Epoch [8/15], Loss: 1.790602207183838\n",
      "Epoch [9/15], Loss: 1.7892343997955322\n",
      "Epoch [10/15], Loss: 1.7879905700683594\n",
      "Epoch [11/15], Loss: 1.7868698835372925\n",
      "Epoch [12/15], Loss: 1.7858672142028809\n",
      "Epoch [13/15], Loss: 1.7849739789962769\n",
      "Epoch [14/15], Loss: 1.7841796875\n",
      "Epoch [15/15], Loss: 1.7834731340408325\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "training_data = data[:, 0].reshape(-1, 1).float()\n",
    "targets = data[:, 1].long()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(training_data)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs,targets)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print training statistics\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=1, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0132, 0.0089, 0.0894, 0.3658, 0.4615, 0.0613]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([5.0]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[:1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    training_data[:1, :],\n",
    "    \"nn.onnx\",\n",
    "    export_params=True,\n",
    "    opset_version=10,\n",
    "    input_names = ['input'],\n",
    "    output_names = ['output'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "onnx_model = onnx.load(\"nn.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ir_version: 5\n",
       "opset_import {\n",
       "  version: 10\n",
       "}\n",
       "producer_name: \"pytorch\"\n",
       "producer_version: \"2.1.1\"\n",
       "graph {\n",
       "  node {\n",
       "    input: \"input\"\n",
       "    output: \"/Relu_output_0\"\n",
       "    name: \"/Relu\"\n",
       "    op_type: \"Relu\"\n",
       "  }\n",
       "  node {\n",
       "    input: \"/Relu_output_0\"\n",
       "    input: \"fc1.weight\"\n",
       "    input: \"fc1.bias\"\n",
       "    output: \"/fc1/Gemm_output_0\"\n",
       "    name: \"/fc1/Gemm\"\n",
       "    op_type: \"Gemm\"\n",
       "    attribute {\n",
       "      name: \"alpha\"\n",
       "      type: FLOAT\n",
       "      f: 1\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"beta\"\n",
       "      type: FLOAT\n",
       "      f: 1\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"transB\"\n",
       "      type: INT\n",
       "      i: 1\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"/fc1/Gemm_output_0\"\n",
       "    input: \"fc2.weight\"\n",
       "    input: \"fc2.bias\"\n",
       "    output: \"/fc2/Gemm_output_0\"\n",
       "    name: \"/fc2/Gemm\"\n",
       "    op_type: \"Gemm\"\n",
       "    attribute {\n",
       "      name: \"alpha\"\n",
       "      type: FLOAT\n",
       "      f: 1\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"beta\"\n",
       "      type: FLOAT\n",
       "      f: 1\n",
       "    }\n",
       "    attribute {\n",
       "      name: \"transB\"\n",
       "      type: INT\n",
       "      i: 1\n",
       "    }\n",
       "  }\n",
       "  node {\n",
       "    input: \"/fc2/Gemm_output_0\"\n",
       "    output: \"output\"\n",
       "    name: \"/Softmax\"\n",
       "    op_type: \"Softmax\"\n",
       "    attribute {\n",
       "      name: \"axis\"\n",
       "      type: INT\n",
       "      i: 1\n",
       "    }\n",
       "  }\n",
       "  name: \"main_graph\"\n",
       "  initializer {\n",
       "    dims: 50\n",
       "    dims: 1\n",
       "    data_type: 1\n",
       "    name: \"fc1.weight\"\n",
       "    raw_data: \"2\\213\\026?\\241\\277i?O\\221B?\\017\\242\\344>\\231\\'\\177\\277\\276\\364[?\\006O\\232>;\\356\\032\\276\\2253q?\\374\\177o\\277\\347*L>\\366\\324o\\277|!\\023?\\344oX>\\356\\312\\230\\276V8L>\\203\\373H\\276\\340\\313L?\\356\\005\\351\\276\\211\\362e\\273\\353\\302\\324>:\\033\\312>\\025\\235\\326\\2763\\300\\\"?\\216\\033\\025?\\340\\010k\\277e\\242\\255\\275c X?\\206\\260B?s(\\353>\\311\\377\\236\\276\\355\\004\\361=$\\024>=\\2044\\007?\\365\\347N?\\231\\\\9\\277\\032OE?5lf?\\331\\362\\'\\277\\301\\275\\307>\\245\\344\\300\\274\\020\\221\\245=\\201\\366W?z\\023\\006\\277\\277\\360\\013=\\366\\320h>\\273\\0349\\277d\\346\\350\\276x\\203t\\277#\\336l?\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 50\n",
       "    data_type: 1\n",
       "    name: \"fc1.bias\"\n",
       "    raw_data: \"u,a\\277]\\355\\345\\276\\t\\312`\\277E\\3348\\277\\314\\0039\\277O@\\020?<\\323W?\\301\\244G\\2766k\\007\\277\\356\\014)?\\306\\355c?l4\\220\\276\\213\\037k?Ud\\353>1?\\344\\275\\374\\320Y?I_\\312>9\\037Z\\276\\263\\001\\323\\2768\\355\\003?\\255l`>\\237\\277`\\276\\013\\214\\314<\\t\\312\\326>\\207@\\226>\\310\\306\\033\\277\\341kh\\277H\\304)>nj\\200\\276\\\\\\357C?\\010\\353q?\\004-\\233>\\231\\302\\231>\\320\\221(>\\213\\017V?K\\212a>f\\\\A>\\021qG?\\214\\362\\026\\277p\\232\\356>3\\256\\323\\274\\323r\\341>\\363\\003n?9\\031!?\\317`\\'>m\\277;\\277\\330\\304\\364=q\\334\\000?\\031\\266\\027\\276\\256\\277\\023?\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 6\n",
       "    dims: 50\n",
       "    data_type: 1\n",
       "    name: \"fc2.weight\"\n",
       "    raw_data: \"\\010F\\313\\2757>\\225\\275%&\\347\\27575,=\\207V\\243=\\010\\345\\202\\275Rk\\204=\\362d\\340\\275\\317oS\\275h\\320:=J\\210\\363\\275#\\213]\\275\\331\\205\\255=\\350}3\\273\\177\\244\\316\\275\\rx\\r>i\\341\\204\\275Z`\\r>\\031\\t5\\274\\307B.\\275\\'\\360\\227=\\025\\327|<_\\252\\327=\\0321\\356<+0\\005>j\\362&=n\\021\\322\\274\\331to<\\031\\207\\326=n/X\\275\\346\\200\\233\\275\\305\\014\\213=\\251\\271\\013>\\374A\\017<\\227\\312[\\2757V\\005\\276+\\224\\263\\275-\\001\\231\\275W\\235\\333\\275K\\352\\372\\275\\336\\377\\013>S\\267\\263=\\216i\\206\\275O\\022\\017\\274$\\264\\034=p\\177V=\\331\\227\\353\\274\\204J\\227\\275\\364i\\025<\\352\\254\\326\\275\\375\\315\\226=6\\244\\035=\\342C\\271=\\211\\232\\360\\275$\\302\\202\\275\\303(\\266=\\035\\246\\r>\\005\\037\\023\\275\\236\\242\\236\\275\\237\\331*=\\363\\374\\310\\275V\\322\\361\\275\\244\\347\\321=^\\374\\367\\275`\\316\\222=l\\024\\320=\\031\\312\\211=\\321:\\341\\275\\321.\\004=#\\355G=\\017D\\276\\275\\0302\\227;\\n\\034>\\275ye\\326;\\nr\\367<\\373\\301\\317<d\\376\\276=\\254\\032\\017\\276.\\202\\005>\\021\\010\\013\\276\\305T\\240\\275\\241v\\225\\275i+\\372\\275\\304W\\210\\275I\\034\\325\\275OK\\356\\275\\2051.\\274\\314h\\346<\\362I\\224\\275+\\030\\345<\\236\\032\\261<\\371\\306\\247\\275\\244\\3207\\275\\035\\005\\206<\\371+\\005\\275\\210\\\"\\017\\275\\367\\014\\206=\\351\\020\\271\\273\\204\\007\\247=\\177U\\304\\275\\376u\\240\\275\\360\\202\\243<\\'\\270\\204\\272\\364\\367\\n>p\\240\\366=\\324\\026\\353\\275x\\357/\\275\\316+\\006>Mx\\325=m^`\\275\\265e,\\275\\261\\220p\\275\\267\\271\\016\\274B\\275B=9\\343\\270\\275#P1=\\206jz=d\\220\\350=\\220\\2634\\275\\035\\326\\305=\\220v_={\\363~\\274Bvk=\\227\\024\\r>\\376t\\302\\273\\377Y\\275\\275\\271t\\014\\276\\030\\n\\013>/\\222\\010>sW\\327\\274Q\\236\\260<\\003\\252\\317=\\020i^=*\\234\\273\\275\\342\\212\\r\\275\\212\\324\\254\\27594\\311\\275\\254o\\302\\274,\\335\\213=VQQ\\275i+\\246\\275\\240\\265*<\\266\\356\\325=\\351Q0=\\273\\266\\202<\\332_\\220\\275\\367\\345~=\\023\\376\\323=h\\204E\\275\\350F\\251\\275L\\201\\263=y\\357\\361=\\324^{=\\302\\312\\307<H\\r&\\275{E\\254==\\260\\326\\2750~\\025\\274=\\323\\203=\\024 \\260=\\330\\330j\\274FU$=\\342\\256$=\\361\\213K=\\361\\276\\'=v\\370\\036\\274}\\323\\267=\\020\\261\\017=\\014\\260\\023>`\\365\\030\\274\\353kX\\275t\\3712=\\202$Y\\274^\\030V=T\\303\\377=\\032w\\323\\275\\350*\\001=gm\\312\\275\\375H\\300\\271kA\\241=Z\\034\\264=7\\222\\311=\\035\\315\\334=g,\\021;g\\362\\\\=\\316\\345\\250\\275\\307,\\007\\275\\034\\273\\202\\273\\363U\\256\\275\\333\\246\\261=FeE=I\\202\\034=\\275\\0149=\\261!\\203\\275\\373\\247z\\275X\\351E=\\217\\222\\212<\\335al=D\\362\\350\\2753\\361\\017\\276\\004\\217\\205\\275\\237\\320\\264=\\367\\003\\006\\276\\006\\347\\271\\275}~c=\\300\\266\\351\\275\\207\\241o\\275\\023\\315\\325\\275uV%\\274\\266s\\027\\275\\324\\006\\377=v\\024\\367\\275w\\327\\014=\\022\\\"\\304\\275\\202dW\\275Qd\\010\\276\\246>\\016\\276v\\370\\000>\\022\\232\\242\\275\\301\\202\\010>\\370\\006\\353\\273\\363\\224\\224\\274C\\227\\344\\275AV\\325=\\016\\333\\r=\\356n\\004\\275\\031\\004\\003\\276\\322\\260B=\\003\\201\\213\\275=\\005\\224\\274\\356\\327\\233\\275W\\330U=\\200\\360\\236\\274\\277\\207\\310=\\340K\\240=\\336\\237\\231=\\244\\204B\\275k0E=\\213\\023\\203\\274\\002\\211\\n>\\367\\315^\\275\\212\\263\\000\\2759\\304\\375<\\3533\\346\\275\\243u\\r>I\\350\\325<$\\307\\001>?\\016\\350\\275\\035\\340\\310<\\267\\332\\003>P\\3251<0\\373\\256=\\322{\\230\\275y\\313\\220\\275%~\\205\\275\\263\\307\\311=As\\342=T\\017\\213\\2741o\\234\\274\\277m\\322\\275\\377\\216\\237=mU\\n\\276!\\200\\357\\275\\307\\221\\261\\274]\\235\\212\\273\\211\\243f\\275\\257\\\"_=\\330\\335\\375\\274Eq\\313\\273r\\221\\350:\\245I7=b\\334\\267\\275\\r\\234\\303=\\243\\255\\206<\\243/\\304\\275\\026@\\237<\\236Yv\\275cs\\004\\275\\023$\\256\\275B\\325D\\275\\302J\\253\\275\\240z\\002\\275Vz^=\\231j\\t=,B\\251=\\357\\rB\\274R%\\255\\274\\210\\034\\370\\275\\2428\\312\\274\\255\\017\\007\\275P\\001\\266=\\237\\273\\366\\2741\\016\\303\\275\\253\\372\\327=T\\'\\256\\275\\000\\\"\\017>\\230\\272\\307\\275\\323\\006\\r\\276\\306\\371\\227\\274*T\\376=\"\n",
       "  }\n",
       "  initializer {\n",
       "    dims: 6\n",
       "    data_type: 1\n",
       "    name: \"fc2.bias\"\n",
       "    raw_data: \"d\\255\\000<\\r\\247\\034=p\\252Y\\274=\\026\\031\\273\\322Y@<\\241p\\323\\274\"\n",
       "  }\n",
       "  input {\n",
       "    name: \"input\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 76\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 1\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  output {\n",
       "    name: \"output\"\n",
       "    type {\n",
       "      tensor_type {\n",
       "        elem_type: 1\n",
       "        shape {\n",
       "          dim {\n",
       "            dim_value: 76\n",
       "          }\n",
       "          dim {\n",
       "            dim_value: 6\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
